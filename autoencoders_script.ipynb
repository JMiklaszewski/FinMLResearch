{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "# Add the current directory to system path\n",
    "sys.path.append(cur_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Prepare sample data\n",
    "timestamp = pd.date_range(start='2020-01-01', periods=300, freq='D')\n",
    "time_series = pd.DataFrame({'values': np.random.randn(300)}, index=timestamp)\n",
    "labels = pd.DataFrame({'label': np.random.randint(0, 3, size=300)}, index=timestamp)\n",
    "ext_features = pd.DataFrame({\n",
    "    'feature1': np.random.randn(300),\n",
    "    'feature2': np.random.randn(300)\n",
    "}, index=timestamp)\n",
    "\n",
    "combined_data = time_series.join(labels).join(ext_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Validation / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation / Test Split\n",
    "train_data = combined_data[:100]\n",
    "val_data = combined_data[100:200]\n",
    "test_data = combined_data[200:]\n",
    "\n",
    "# Read targets\n",
    "train_target = train_data.label.values\n",
    "val_target = val_data.label.values\n",
    "test_target = test_data.label.values\n",
    "\n",
    "# Read features\n",
    "train_features = train_data[['feature1', 'feature2']].values\n",
    "val_features = val_data[['feature1', 'feature2']].values\n",
    "test_features = test_data[['feature1', 'feature2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pl_model_utils import TimeSeriesDataModule\n",
    "# Instantiate data module and model\n",
    "data_module = TimeSeriesDataModule(\n",
    "    train_target, train_features,\n",
    "    val_target, val_features,\n",
    "    test_target, test_features,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Setup the data for model\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Basic Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile simple Autoencoder for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_autoencoder_classifiers import AutoencoderClassifier\n",
    "ae_model = AutoencoderClassifier(context_length=1, num_classes=3, num_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# Define a checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | encoder    | Sequential | 8.8 K \n",
      "1 | decoder    | Sequential | 8.4 K \n",
      "2 | classifier | Sequential | 2.2 K \n",
      "3 | softmax    | Softmax    | 0     \n",
      "------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 80.14it/s, v_num=41] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 62.01it/s, v_num=41]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "# Train the model\n",
    "trainer = Trainer(max_epochs=20, callbacks=[checkpoint_callback])\n",
    "trainer.fit(ae_model, data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'num_heads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpl_model_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate_model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAutoencoderClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jedre\\OneDrive\\Pulpit\\State Street\\Programs\\Python\\ML Research Project 2024\\Autoencoder\\pl_model_utils.py:102\u001b[0m, in \u001b[0;36mcross_validate_model\u001b[1;34m(X, y, model_class, context_length, num_classes, num_features, n_splits, num_heads, dropout_prob, hidden_units, embed_dim, classifier_units, lr)\u001b[0m\n\u001b[0;32m     94\u001b[0m train_data \u001b[38;5;241m=\u001b[39m DataLoader(TimeSeriesDataset(\n\u001b[0;32m     95\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(y[train_index], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), \n\u001b[0;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(X[train_index], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     98\u001b[0m val_data \u001b[38;5;241m=\u001b[39m DataLoader(TimeSeriesDataset(\n\u001b[0;32m     99\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(y[test_index], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), \n\u001b[0;32m    100\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(X[test_index], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m--> 102\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m    114\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_data)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_heads'"
     ]
    }
   ],
   "source": [
    "from pl_model_utils import cross_validate_model\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate_model(data_module.val_features, data_module.val_target, AutoencoderClassifier, context_length=1, num_classes=3, num_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictions with MC Dropout Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_model_utils import mc_dropout_predictions\n",
    "# Perform MC Dropout predictions\n",
    "mc_predictions = mc_dropout_predictions(ae_model, data_module.test_dataloader())\n",
    "# Calculate mean and standard deviation for uncertainty estimates\n",
    "mean_predictions = mc_predictions.mean(axis=0)\n",
    "std_predictions = mc_predictions.std(axis=0)\n",
    "# Convert mean predictions to class labels\n",
    "predicted_labels = np.argmax(mean_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Attention-Enchanced Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pl_autoencoder_classifiers import AutoencoderAttentionClassifier\n",
    "from pl_model_utils import TimeSeriesDataset\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def ae_attention_objective(trial):\n",
    "    context_length = 1\n",
    "    num_classes = 3\n",
    "    num_features = 2\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_categorical('lr', [1e-5, 1e-3, 1e-2])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [1, 2, 4])\n",
    "    dropout_prob = trial.suggest_categorical('dropout_prob', [0.1, 0.3, 0.5])\n",
    "    hidden_units = trial.suggest_categorical('hidden_units', [64, 128, 256])\n",
    "    embed_dim = trial.suggest_categorical('embed_dim', [32, 64, 128])\n",
    "    classifier_units = trial.suggest_categorical('classifier_units', [16, 32, 64])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    # Initialize the model with suggested hyperparameters\n",
    "    model = AutoencoderAttentionClassifier(\n",
    "        context_length=context_length,\n",
    "        num_classes=num_classes,\n",
    "        num_features=num_features,\n",
    "        num_heads=num_heads,\n",
    "        dropout_prob=dropout_prob,\n",
    "        hidden_units=hidden_units,\n",
    "        embed_dim=embed_dim,\n",
    "        classifier_units=classifier_units,\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    # Assuming you have your dataset in `X` and `y`\n",
    "    X, y = data_module.val_features, data_module.val_target\n",
    "    # X = np.array(X_train)  # Ensure X_train is a NumPy array\n",
    "    # y = np.array(y_train)  # Ensure y_train is a NumPy array\n",
    "\n",
    "    # Time series split\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        # Create DataLoader for the training and validation fold\n",
    "        train_dataset = TimeSeriesDataset(\n",
    "            torch.tensor(y_train_fold, dtype=torch.float32), \n",
    "            torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "            )\n",
    "        \n",
    "        val_dataset = TimeSeriesDataset(\n",
    "            torch.tensor(y_val_fold, dtype=torch.float32), \n",
    "            torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "            )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=10,\n",
    "            callbacks=[EarlyStopping(monitor='train_loss', patience=3, mode='min')],\n",
    "            logger=False,\n",
    "            enable_checkpointing=False\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, train_loader)\n",
    "\n",
    "        # Validate the model\n",
    "\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                targets, features = batch\n",
    "                _, classification = model(targets, features)\n",
    "                # preds = torch.argmax(classification, dim=1)\n",
    "                all_preds.extend(classification.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        # val_predictions = trainer.predict(model, val_loader)\n",
    "        # val_predictions = torch.cat([x for x in val_predictions], dim=0).numpy()\n",
    "        \n",
    "        val_loss = log_loss(all_targets, all_preds)\n",
    "        cv_scores.append(val_loss)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:46:29,096] A new study created in memory with name: no-name-df67b1ea-18ca-4025-a4de-62baeb978f75\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 65.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 54.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 49.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 48.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 55.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 51.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:46:31,215] Trial 0 finished with value: 3.825281085309706 and parameters: {'lr': 0.01, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 16, 'batch_size': 32}. Best is trial 0 with value: 3.825281085309706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 65.83it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 74.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 63.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 57.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 77.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:33,873] Trial 1 finished with value: 1.1083560701727004 and parameters: {'lr': 1e-05, 'num_heads': 2, 'dropout_prob': 0.3, 'hidden_units': 128, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 16}. Best is trial 1 with value: 1.1083560701727004.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 64.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 52.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 64.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 56.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 79.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 62.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 73.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 68.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:36,150] Trial 2 finished with value: 0.2628563712940483 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 2 with value: 0.2628563712940483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 70.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 66.62it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 65.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 70.06it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 65.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 6/6 [00:00<00:00, 73.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:39,278] Trial 3 finished with value: 0.49741824650347377 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.5, 'hidden_units': 128, 'embed_dim': 128, 'classifier_units': 32, 'batch_size': 16}. Best is trial 2 with value: 0.2628563712940483.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "36.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.0 K    Total params\n",
      "0.144     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 51.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "36.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.0 K    Total params\n",
      "0.144     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 68.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 58.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "36.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.0 K    Total params\n",
      "0.144     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 70.11it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 64.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "36.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.0 K    Total params\n",
      "0.144     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 71.45it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "36.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.0 K    Total params\n",
      "0.144     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 71.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 64.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:41,256] Trial 4 finished with value: 0.6473592468628939 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.5, 'hidden_units': 128, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 2 with value: 0.2628563712940483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 579   \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "13.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.8 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 80.99it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 69.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 579   \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "13.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.8 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 86.61it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 579   \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "13.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.8 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 84.72it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 579   \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "13.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.8 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 83.41it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 579   \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "13.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.8 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 79.30it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:46:43,072] Trial 5 finished with value: 4.846898171504426 and parameters: {'lr': 0.01, 'num_heads': 2, 'dropout_prob': 0.3, 'hidden_units': 128, 'embed_dim': 32, 'classifier_units': 16, 'batch_size': 16}. Best is trial 2 with value: 0.2628563712940483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 66.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 67.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 70.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 59.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:44,581] Trial 6 finished with value: 0.33566679588833914 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 32, 'batch_size': 64}. Best is trial 2 with value: 0.2628563712940483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 68.59it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 81.45it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 67.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 64.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 69.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:46,786] Trial 7 finished with value: 7.541220984850528 and parameters: {'lr': 0.01, 'num_heads': 4, 'dropout_prob': 0.5, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 16}. Best is trial 2 with value: 0.2628563712940483.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 49.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 51.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 49.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 70.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 58.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:48,711] Trial 8 finished with value: 0.311609679585559 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 128, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 2 with value: 0.2628563712940483.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 68.90it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 59.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 70.50it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 64.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 66.63it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 62.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 77.11it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 47.15it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:52,149] Trial 9 finished with value: 0.2145850367803986 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 46.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 44.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 48.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 48.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 6/6 [00:00<00:00, 48.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:56,030] Trial 10 finished with value: 1.1252722474326784 and parameters: {'lr': 1e-05, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 48.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 47.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 45.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:46:59,315] Trial 11 finished with value: 0.24129068870706707 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 45.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 44.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:02,959] Trial 12 finished with value: 0.31196286627638725 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 49.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:05,917] Trial 13 finished with value: 0.3384241843310133 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 43.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 43.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 54.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 47.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:08,693] Trial 14 finished with value: 0.3116994100143443 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 64}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 40.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 74.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 72.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 70.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:11,412] Trial 15 finished with value: 1.1054897126470344 and parameters: {'lr': 1e-05, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 62.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 48.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 67.15it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 58.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 73.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 74.42it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 67.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 62.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:13,513] Trial 16 finished with value: 0.28472063048473817 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 16, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 74.21it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 77.57it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 68.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 77.01it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 62.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 69.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 62.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "29.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.6 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 66.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:15,610] Trial 17 finished with value: 0.4367601101291384 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 59.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 54.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 40.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:47:18,335] Trial 18 finished with value: 23.09204652528175 and parameters: {'lr': 0.01, 'num_heads': 2, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 32.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 34.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 39.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:20,339] Trial 19 finished with value: 1.1191742897936097 and parameters: {'lr': 1e-05, 'num_heads': 1, 'dropout_prob': 0.5, 'hidden_units': 256, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 64}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "26.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 K    Total params\n",
      "0.105     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "26.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 K    Total params\n",
      "0.105     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 44.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "26.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 K    Total params\n",
      "0.105     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 47.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 45.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "26.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 K    Total params\n",
      "0.105     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 62.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 58.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.4 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 4.2 K \n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "26.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 K    Total params\n",
      "0.105     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 48.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 46.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:25,619] Trial 20 finished with value: 0.41871283865831305 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 64, 'classifier_units': 16, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 48.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 48.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3/3 [00:00<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:28,981] Trial 21 finished with value: 0.2325607548094193 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 48.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 31.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:32,773] Trial 22 finished with value: 0.3339064796881317 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 35.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 38.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 42.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:36,437] Trial 23 finished with value: 0.3023341387485059 and parameters: {'lr': 0.001, 'num_heads': 2, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 44.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 55.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 41.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:39,548] Trial 24 finished with value: 0.26077531725798253 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 45.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 47.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 46.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:43,041] Trial 25 finished with value: 0.335423145906064 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 46.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 35.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 13.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 13.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 41.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:46,270] Trial 26 finished with value: 0.266045326904529 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 67.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 63.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 78.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 70.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3/3 [00:00<00:00, 69.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:48,818] Trial 27 finished with value: 0.2740490051183773 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 61.85it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 48.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 42.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 46.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 58.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 52.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 51.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:50,328] Trial 28 finished with value: 5.704488703891032 and parameters: {'lr': 0.01, 'num_heads': 2, 'dropout_prob': 0.5, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 16, 'batch_size': 64}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 76.64it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 64.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 70.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4/4 [00:00<00:00, 72.25it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 70.61it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 2.3 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 2.2 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 74.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:52,943] Trial 29 finished with value: 1.1161627722061627 and parameters: {'lr': 1e-05, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 64, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 57.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 71.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 62.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 40.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 1.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "52.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.1 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3/3 [00:00<00:00, 41.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:55,484] Trial 30 finished with value: 1.2562753628038212 and parameters: {'lr': 0.01, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 16, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 47.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 44.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:47:58,723] Trial 31 finished with value: 0.26083722789739483 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 47.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:02,307] Trial 32 finished with value: 0.31975252200768955 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 49.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 44.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:05,411] Trial 33 finished with value: 0.30807236443790714 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 44.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 42.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 44.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:08,617] Trial 34 finished with value: 0.28271483965811195 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 50.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 43.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:11,779] Trial 35 finished with value: 0.3409548341372168 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 128, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 56.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4/4 [00:00<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 45.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 45.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:16,387] Trial 36 finished with value: 0.2801207295404994 and parameters: {'lr': 0.001, 'num_heads': 2, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 35.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:00<00:00, 47.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.8 K \n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 8.4 K \n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "38.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.2 K    Total params\n",
      "0.153     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:19,353] Trial 37 finished with value: 0.7250761804082936 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.5, 'hidden_units': 128, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 39.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 43.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 40.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 48.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "137 K     Trainable params\n",
      "0         Non-trainable params\n",
      "137 K     Total params\n",
      "0.550     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 44.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 43.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:23,855] Trial 38 finished with value: 1.092792756686184 and parameters: {'lr': 1e-05, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 32, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 49.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 64.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 55.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 66.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 59.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 70.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 64.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 2.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "53.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.2 K    Total params\n",
      "0.213     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 68.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 63.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:26,329] Trial 39 finished with value: 0.3383194780579354 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 32, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 72.24it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 63.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 72.46it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 66.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4/4 [00:00<00:00, 69.02it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 80.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:28,765] Trial 40 finished with value: 2.1423536861242303 and parameters: {'lr': 0.01, 'num_heads': 1, 'dropout_prob': 0.3, 'hidden_units': 128, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 16}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 58.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 67.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 58.29it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 52.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 60.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 41.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:31,183] Trial 41 finished with value: 0.2685410893419337 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 11.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 40.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 48.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 43.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:34,702] Trial 42 finished with value: 0.34106235931538353 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 52.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 47.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:38,464] Trial 43 finished with value: 0.2736863209705603 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 45.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 41.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:41,952] Trial 44 finished with value: 0.26981340312402124 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 32}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 29.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 43.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.5 K\n",
      "1 | attention  | MultiheadAttention | 16.6 K\n",
      "2 | decoder    | Sequential         | 16.9 K\n",
      "3 | classifier | Sequential         | 4.4 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "55.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.4 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 37.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:44,463] Trial 45 finished with value: 0.7377225082818052 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.5, 'hidden_units': 256, 'embed_dim': 64, 'classifier_units': 64, 'batch_size': 64}. Best is trial 9 with value: 0.2145850367803986.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 32.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 35.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:48,526] Trial 46 finished with value: 0.19394654738365386 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 32}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "85.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "85.1 K    Total params\n",
      "0.340     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "85.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "85.1 K    Total params\n",
      "0.340     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 25.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "85.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "85.1 K    Total params\n",
      "0.340     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "85.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "85.1 K    Total params\n",
      "0.340     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:00<00:00, 41.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "85.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "85.1 K    Total params\n",
      "0.340     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 42.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 39.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:52,017] Trial 47 finished with value: 0.3379355234081705 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 128, 'classifier_units': 16, 'batch_size': 32}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:00<00:00, 37.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 46.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 4.2 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 47.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:55,747] Trial 48 finished with value: 1.1452058147971338 and parameters: {'lr': 1e-05, 'num_heads': 2, 'dropout_prob': 0.1, 'hidden_units': 128, 'embed_dim': 128, 'classifier_units': 32, 'batch_size': 16}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:48:58,666] Trial 49 finished with value: 0.2181680900682398 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 38.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 50.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 31.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 53.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:01,766] Trial 50 finished with value: 0.24096010375063198 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 53.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 53.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 58.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 50.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 56.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:03,906] Trial 51 finished with value: 0.22942472770444336 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 47.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 65.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 50.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 47.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 48.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 58.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 49.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:06,092] Trial 52 finished with value: 0.22378121843032087 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 55.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 49.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 42.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:07,935] Trial 53 finished with value: 0.23028905295446184 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 22.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 33.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:10,774] Trial 54 finished with value: 0.223393749355245 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 36.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 34.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:13,660] Trial 55 finished with value: 0.27267406674265005 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 37.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 36.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:49:15,914] Trial 56 finished with value: 8.074552665933124 and parameters: {'lr': 0.01, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 28.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 30.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:19,538] Trial 57 finished with value: 0.7033978015678368 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.5, 'hidden_units': 64, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 83.49it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 61.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 57.93it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:22,378] Trial 58 finished with value: 0.2669066875263125 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 51.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 23.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 22.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:25,138] Trial 59 finished with value: 0.3000648618333367 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 42.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 34.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:27,699] Trial 60 finished with value: 0.30452507674750984 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 46 with value: 0.19394654738365386.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 39.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 33.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:30,595] Trial 61 finished with value: 0.18858144789630626 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 34.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:33,548] Trial 62 finished with value: 0.2708727500943576 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 39.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:36,267] Trial 63 finished with value: 0.19911526233070517 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 64.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 56.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 54.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:39,160] Trial 64 finished with value: 0.23383833110374477 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 47.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 37.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:40,705] Trial 65 finished with value: 1.099523532316726 and parameters: {'lr': 1e-05, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 53.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 55.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 45.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 56.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 66.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 57.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:42,682] Trial 66 finished with value: 0.26244306453820376 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 16, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 46.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 53.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 42.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 55.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 45.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:44,756] Trial 67 finished with value: 0.2533099196490101 and parameters: {'lr': 0.001, 'num_heads': 2, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 38.37it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 25.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 17:49:46,416] Trial 68 finished with value: 15.226121909830852 and parameters: {'lr': 0.01, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 64, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 35.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 33.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 33.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:49,239] Trial 69 finished with value: 0.26160692204404373 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 36.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 17.0 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 16.6 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:51,940] Trial 70 finished with value: 0.6430470494806036 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.5, 'hidden_units': 128, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 40.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 37.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:55,049] Trial 71 finished with value: 0.18949483868029332 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 36.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:49:57,749] Trial 72 finished with value: 0.20700840945363547 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 45.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 31.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 32.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 25.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:00,555] Trial 73 finished with value: 0.2257405125854696 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 43.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 45.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 44.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 49.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 9.2 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 8.7 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00, 38.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:03,410] Trial 74 finished with value: 0.5326950982771096 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 64}. Best is trial 61 with value: 0.18858144789630626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 41.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 46.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:07,741] Trial 75 finished with value: 0.1359277220447974 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 75 with value: 0.1359277220447974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 53.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 58.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 54.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 36.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 44.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 42.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 43.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:12,255] Trial 76 finished with value: 0.13451480735448582 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 76 with value: 0.13451480735448582.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 59.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 51.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 47.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 42.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 56.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:16,491] Trial 77 finished with value: 0.2934783062880756 and parameters: {'lr': 0.001, 'num_heads': 4, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 16, 'batch_size': 16}. Best is trial 76 with value: 0.13451480735448582.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00, 60.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 61.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 56.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 4/4 [00:00<00:00, 60.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 64.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 60.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:19,281] Trial 78 finished with value: 1.099978349431081 and parameters: {'lr': 1e-05, 'num_heads': 2, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 76 with value: 0.13451480735448582.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 61.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 53.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 63.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 56.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4/4 [00:00<00:00, 62.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 65.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 62.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 63.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:23,262] Trial 79 finished with value: 0.1637085773790498 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 76 with value: 0.13451480735448582.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 37.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 41.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:27,845] Trial 80 finished with value: 0.13831852558336405 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 76 with value: 0.13451480735448582.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 38.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 35.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4/4 [00:00<00:00, 47.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 50.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 46.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:32,915] Trial 81 finished with value: 0.0960632309753097 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 47.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 39.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 40.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:36,930] Trial 82 finished with value: 0.21326530240749447 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 43.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:41,135] Trial 83 finished with value: 0.12821233522876796 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 43.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 42.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 37.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 35.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 40.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 49.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:46,589] Trial 84 finished with value: 0.11666364889947922 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 33.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:51,894] Trial 85 finished with value: 0.14362008244313157 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 35.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 56.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 50.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 48.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 46.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 65.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:56,959] Trial 86 finished with value: 0.09677550371826343 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.87it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 65.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 61.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 73.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 83.61it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 4.6 K \n",
      "1 | attention  | MultiheadAttention | 4.2 K \n",
      "2 | decoder    | Sequential         | 4.4 K \n",
      "3 | classifier | Sequential         | 2.3 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 72.61it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:50:59,532] Trial 87 finished with value: 1.1612743207325493 and parameters: {'lr': 0.01, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 128, 'embed_dim': 32, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 60.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 54.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 76.44it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 68.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 59.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 62.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 40.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:03,278] Trial 88 finished with value: 0.11508932005620169 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 34.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 43.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 42.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 40.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 8.6 K \n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 8.3 K \n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.366     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 46.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 44.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:08,755] Trial 89 finished with value: 0.6759958870532523 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.5, 'hidden_units': 64, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 39.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 42.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 39.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 49.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:13,836] Trial 90 finished with value: 0.141199752062485 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 38.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 44.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 41.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:18,090] Trial 91 finished with value: 0.1259503197714127 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 42.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 43.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 53.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 43.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:22,496] Trial 92 finished with value: 0.13143346722874721 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 34.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 44.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4/4 [00:00<00:00, 41.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:00<00:00, 43.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:27,372] Trial 93 finished with value: 0.13737095097967894 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 43.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 39.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4/4 [00:00<00:00, 42.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 44.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 42.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 66.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:32,391] Trial 94 finished with value: 0.2892074725463432 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 59.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 53.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 61.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 56.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 62.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 63.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6/6 [00:00<00:00, 66.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:35,441] Trial 95 finished with value: 0.16634088678213693 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 41.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 37.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 69.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 63.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 50.22it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 47.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 61.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 2.1 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6/6 [00:00<00:00, 46.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:38,598] Trial 96 finished with value: 0.23832726138494068 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.3, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 16, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 63.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 55.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 40.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 38.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4/4 [00:00<00:00, 40.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 42.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 40.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6/6 [00:00<00:00, 49.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:43,620] Trial 97 finished with value: 0.14384025931720487 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 36.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:00<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 46.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6/6 [00:00<00:00, 44.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:48,513] Trial 98 finished with value: 1.0926545498486617 and parameters: {'lr': 1e-05, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 46.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00, 40.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 45.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:00<00:00, 41.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4/4 [00:00<00:00, 39.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 40.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 6/6 [00:00<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2942: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "[I 2024-07-17 17:51:53,931] Trial 99 finished with value: 0.13487873163124273 and parameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}. Best is trial 81 with value: 0.0960632309753097.\n"
     ]
    }
   ],
   "source": [
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(ae_attention_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lr': 0.001, 'num_heads': 1, 'dropout_prob': 0.1, 'hidden_units': 256, 'embed_dim': 128, 'classifier_units': 64, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_attention_model = AutoencoderAttentionClassifier(\n",
    "    context_length=1, \n",
    "    num_classes=3, \n",
    "    num_features=2,\n",
    "    lr=study.best_params['lr'],\n",
    "    num_heads=study.best_params['num_heads'],\n",
    "    dropout_prob=study.best_params['dropout_prob'],\n",
    "    hidden_units=study.best_params['hidden_units'],\n",
    "    embed_dim=study.best_params['embed_dim'],\n",
    "    classifier_units=study.best_params['classifier_units']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory c:\\Users\\jedre\\OneDrive\\Pulpit\\State Street\\Programs\\Python\\ML Research Project 2024\\Autoencoder\\lightning_logs\\version_41\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 64.85it/s, v_num=42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 54.91it/s, v_num=42]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer = Trainer(max_epochs=20, callbacks=[checkpoint_callback])\n",
    "trainer.fit(ae_attention_model, data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 47.17it/s, v_num=43]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 30.31it/s, v_num=43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 60.11it/s, v_num=44]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 38.64it/s, v_num=44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 70.61it/s, v_num=45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 53.95it/s, v_num=45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 5/5 [00:00<00:00, 47.16it/s, v_num=46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 5/5 [00:00<00:00, 39.73it/s, v_num=46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder    | Sequential         | 33.9 K\n",
      "1 | attention  | MultiheadAttention | 66.0 K\n",
      "2 | decoder    | Sequential         | 33.3 K\n",
      "3 | classifier | Sequential         | 8.5 K \n",
      "4 | softmax    | Softmax            | 0     \n",
      "--------------------------------------------------\n",
      "141 K     Trainable params\n",
      "0         Non-trainable params\n",
      "141 K     Total params\n",
      "0.567     Total estimated model params size (MB)\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\jedre\\miniconda3\\envs\\GluonTS\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 6/6 [00:00<00:00, 62.39it/s, v_num=47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 6/6 [00:00<00:00, 52.69it/s, v_num=47]\n",
      "Cross-Validation Classification Report:\n",
      "           0.0  1.0  2.0  accuracy  macro avg  weighted avg\n",
      "precision  1.0  1.0  1.0       1.0        1.0           1.0\n",
      "recall     1.0  1.0  1.0       1.0        1.0           1.0\n",
      "f1-score   1.0  1.0  1.0       1.0        1.0           1.0\n",
      "support    7.2  5.2  3.6       1.0       16.0          16.0\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_results = cross_validate_model(\n",
    "    data_module.val_features, \n",
    "    data_module.val_target, \n",
    "    AutoencoderAttentionClassifier, \n",
    "    context_length=1, \n",
    "    num_classes=3, \n",
    "    num_features=2,\n",
    "    lr=study.best_params['lr'],\n",
    "    num_heads=study.best_params['num_heads'],\n",
    "    dropout_prob=study.best_params['dropout_prob'],\n",
    "    hidden_units=study.best_params['hidden_units'],\n",
    "    embed_dim=study.best_params['embed_dim'],\n",
    "    classifier_units=study.best_params['classifier_units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0.0  1.0  2.0  accuracy  macro avg  weighted avg\n",
      "precision  1.0  1.0  1.0       1.0        1.0           1.0\n",
      "recall     1.0  1.0  1.0       1.0        1.0           1.0\n",
      "f1-score   1.0  1.0  1.0       1.0        1.0           1.0\n",
      "support    7.2  5.2  3.6       1.0       16.0          16.0\n"
     ]
    }
   ],
   "source": [
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MC Dropout predictions\n",
    "mc_predictions = mc_dropout_predictions(ae_attention_model, data_module.test_dataloader())\n",
    "# Calculate mean and standard deviation for uncertainty estimates\n",
    "mean_predictions = mc_predictions.mean(axis=0)\n",
    "std_predictions = mc_predictions.std(axis=0)\n",
    "# Convert mean predictions to class labels\n",
    "predicted_labels = np.argmax(mean_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Predicted Label = 2, Probabilities = [8.794023e-13 2.155976e-05 9.999785e-01], Uncertainty (std) = [4.2819121e-12 4.6762838e-05 4.6762609e-05]\n",
      "Sample 1: Predicted Label = 2, Probabilities = [1.6389518e-13 1.7555063e-05 9.9998277e-01], Uncertainty (std) = [1.0847810e-12 3.2813448e-05 3.2815027e-05]\n",
      "Sample 2: Predicted Label = 0, Probabilities = [9.9996918e-01 3.1090702e-05 1.9146974e-13], Uncertainty (std) = [2.4332161e-04 2.4331795e-04 1.7549427e-12]\n",
      "Sample 3: Predicted Label = 0, Probabilities = [9.9999928e-01 8.5255687e-07 3.7035114e-15], Uncertainty (std) = [4.3830778e-06 4.3823616e-06 3.5958063e-14]\n",
      "Sample 4: Predicted Label = 2, Probabilities = [2.5558643e-13 3.4495219e-04 9.9965525e-01], Uncertainty (std) = [1.9162801e-12 2.9945208e-03 2.9945192e-03]\n",
      "Sample 5: Predicted Label = 1, Probabilities = [3.3359454e-04 9.9914080e-01 5.2574102e-04], Uncertainty (std) = [0.00134689 0.00194804 0.00125005]\n",
      "Sample 6: Predicted Label = 0, Probabilities = [9.9999785e-01 2.2749416e-06 4.4643924e-12], Uncertainty (std) = [1.1781105e-05 1.1778559e-05 4.4299564e-11]\n",
      "Sample 7: Predicted Label = 1, Probabilities = [2.0257269e-04 9.9746132e-01 2.3360893e-03], Uncertainty (std) = [0.00046289 0.00431676 0.00434672]\n",
      "Sample 8: Predicted Label = 2, Probabilities = [1.1133056e-11 2.8464716e-04 9.9971545e-01], Uncertainty (std) = [9.7280080e-11 2.3468407e-03 2.3468323e-03]\n",
      "Sample 9: Predicted Label = 0, Probabilities = [9.9999970e-01 4.0916612e-07 1.5231101e-13], Uncertainty (std) = [1.4822754e-06 1.4764255e-06 8.7322548e-13]\n",
      "Sample 10: Predicted Label = 2, Probabilities = [6.9372202e-14 1.7869485e-05 9.9998224e-01], Uncertainty (std) = [3.4380094e-13 3.3380948e-05 3.3384422e-05]\n",
      "Sample 11: Predicted Label = 1, Probabilities = [2.7516828e-04 9.9717337e-01 2.5511419e-03], Uncertainty (std) = [0.0005014  0.01127011 0.01126386]\n",
      "Sample 12: Predicted Label = 1, Probabilities = [3.9189798e-04 9.9897879e-01 6.2907283e-04], Uncertainty (std) = [0.00135974 0.00226605 0.0018817 ]\n",
      "Sample 13: Predicted Label = 0, Probabilities = [9.9999619e-01 3.9406395e-06 1.0435908e-13], Uncertainty (std) = [2.6770182e-05 2.6768137e-05 9.9278951e-13]\n",
      "Sample 14: Predicted Label = 2, Probabilities = [7.667749e-13 8.640156e-05 9.999138e-01], Uncertainty (std) = [5.0758365e-12 3.2980845e-04 3.2981086e-04]\n",
      "Sample 15: Predicted Label = 2, Probabilities = [1.1690721e-11 4.9028131e-05 9.9995130e-01], Uncertainty (std) = [1.12203496e-10 2.02459385e-04 2.02465453e-04]\n",
      "Sample 16: Predicted Label = 2, Probabilities = [3.4686125e-12 4.2830059e-05 9.9995726e-01], Uncertainty (std) = [3.1293166e-11 1.2514950e-04 1.2514529e-04]\n",
      "Sample 17: Predicted Label = 2, Probabilities = [1.3287433e-12 4.7720899e-04 9.9952281e-01], Uncertainty (std) = [8.4814855e-12 2.7578822e-03 2.7578822e-03]\n",
      "Sample 18: Predicted Label = 2, Probabilities = [2.1514987e-13 6.2285119e-04 9.9937737e-01], Uncertainty (std) = [9.960209e-13 5.281197e-03 5.281194e-03]\n",
      "Sample 19: Predicted Label = 2, Probabilities = [2.0625213e-13 2.0088804e-05 9.9998009e-01], Uncertainty (std) = [9.777007e-13 6.370728e-05 6.370790e-05]\n",
      "Sample 20: Predicted Label = 0, Probabilities = [9.9999803e-01 2.0472344e-06 2.2290284e-15], Uncertainty (std) = [7.0176006e-06 7.0110009e-06 1.5156296e-14]\n",
      "Sample 21: Predicted Label = 1, Probabilities = [1.657172e-04 9.984572e-01 1.376819e-03], Uncertainty (std) = [0.00042224 0.0034311  0.00344992]\n",
      "Sample 22: Predicted Label = 0, Probabilities = [9.9998939e-01 1.0708951e-05 1.1305440e-13], Uncertainty (std) = [6.0866896e-05 6.0868668e-05 6.2897208e-13]\n",
      "Sample 23: Predicted Label = 0, Probabilities = [9.9999899e-01 1.0704366e-06 2.6744570e-16], Uncertainty (std) = [4.0953728e-06 4.0952955e-06 1.7301127e-15]\n",
      "Sample 24: Predicted Label = 2, Probabilities = [2.4164446e-12 5.1487736e-05 9.9994874e-01], Uncertainty (std) = [7.393793e-12 9.906163e-05 9.906612e-05]\n",
      "Sample 25: Predicted Label = 0, Probabilities = [9.9999994e-01 1.0931392e-07 6.5769202e-16], Uncertainty (std) = [3.8462318e-07 3.7910260e-07 3.3638105e-15]\n",
      "Sample 26: Predicted Label = 1, Probabilities = [1.4583964e-03 9.9850100e-01 4.0976494e-05], Uncertainty (std) = [0.01366476 0.01366401 0.00031368]\n",
      "Sample 27: Predicted Label = 2, Probabilities = [1.0123165e-11 1.8927632e-05 9.9998122e-01], Uncertainty (std) = [9.9270286e-11 7.5046322e-05 7.5046941e-05]\n",
      "Sample 28: Predicted Label = 1, Probabilities = [1.3388836e-05 9.9930590e-01 6.8080681e-04], Uncertainty (std) = [3.0925530e-05 3.6276360e-03 3.6283834e-03]\n",
      "Sample 29: Predicted Label = 0, Probabilities = [9.9998444e-01 1.5728925e-05 3.6245770e-14], Uncertainty (std) = [1.0688099e-04 1.0688134e-04 1.9673132e-13]\n",
      "Sample 30: Predicted Label = 2, Probabilities = [1.6745543e-12 2.7307586e-05 9.9997276e-01], Uncertainty (std) = [1.0921635e-11 5.8099064e-05 5.8103666e-05]\n",
      "Sample 31: Predicted Label = 0, Probabilities = [9.9999619e-01 3.9108154e-06 2.0352189e-13], Uncertainty (std) = [1.5021718e-05 1.5015048e-05 2.0118616e-12]\n",
      "Sample 32: Predicted Label = 0, Probabilities = [9.9999982e-01 2.0237438e-07 1.3074940e-14], Uncertainty (std) = [1.1316096e-06 1.1352323e-06 1.2586030e-13]\n",
      "Sample 33: Predicted Label = 1, Probabilities = [2.3632578e-04 9.9866813e-01 1.0954705e-03], Uncertainty (std) = [0.00046228 0.00247501 0.00245946]\n",
      "Sample 34: Predicted Label = 0, Probabilities = [9.9999857e-01 1.6220334e-06 1.3978557e-16], Uncertainty (std) = [6.4992137e-06 6.5018162e-06 5.3272459e-16]\n",
      "Sample 35: Predicted Label = 2, Probabilities = [5.2334560e-12 4.3210726e-05 9.9995714e-01], Uncertainty (std) = [3.9873656e-11 2.0254473e-04 2.0254933e-04]\n",
      "Sample 36: Predicted Label = 2, Probabilities = [1.4881070e-11 9.0857990e-05 9.9990916e-01], Uncertainty (std) = [1.03227364e-10 4.13548958e-04 4.13551810e-04]\n",
      "Sample 37: Predicted Label = 2, Probabilities = [5.4672451e-12 5.0214036e-05 9.9995005e-01], Uncertainty (std) = [3.0147829e-11 1.8433978e-04 1.8434557e-04]\n",
      "Sample 38: Predicted Label = 0, Probabilities = [9.9999982e-01 2.3762146e-07 2.0120427e-16], Uncertainty (std) = [1.0973084e-06 1.0954351e-06 1.1623139e-15]\n",
      "Sample 39: Predicted Label = 1, Probabilities = [2.3551942e-05 9.9920928e-01 7.6708733e-04], Uncertainty (std) = [4.6373916e-05 4.1997279e-03 4.2020348e-03]\n",
      "Sample 40: Predicted Label = 1, Probabilities = [2.4722816e-04 9.9710292e-01 2.6501240e-03], Uncertainty (std) = [0.00047865 0.01577283 0.01579899]\n",
      "Sample 41: Predicted Label = 0, Probabilities = [9.9999994e-01 1.2409443e-07 1.8472068e-16], Uncertainty (std) = [7.4130543e-07 7.3311145e-07 1.8299764e-15]\n",
      "Sample 42: Predicted Label = 0, Probabilities = [9.9882013e-01 1.1799007e-03 1.8909350e-15], Uncertainty (std) = [6.0847411e-03 6.0847467e-03 9.0988466e-15]\n",
      "Sample 43: Predicted Label = 2, Probabilities = [3.9341863e-10 4.9051031e-04 9.9950927e-01], Uncertainty (std) = [3.2551157e-09 1.6881160e-03 1.6881182e-03]\n",
      "Sample 44: Predicted Label = 2, Probabilities = [1.4576043e-11 6.2329427e-04 9.9937677e-01], Uncertainty (std) = [9.9456741e-11 2.5171658e-03 2.5171640e-03]\n",
      "Sample 45: Predicted Label = 2, Probabilities = [4.6086193e-13 2.6446238e-05 9.9997377e-01], Uncertainty (std) = [1.7656611e-12 7.9249199e-05 7.9253485e-05]\n",
      "Sample 46: Predicted Label = 1, Probabilities = [2.9482497e-04 9.9788970e-01 1.8154663e-03], Uncertainty (std) = [0.00053562 0.00419755 0.00416998]\n",
      "Sample 47: Predicted Label = 0, Probabilities = [9.9999994e-01 2.0013900e-07 1.2652872e-15], Uncertainty (std) = [7.1911961e-07 7.0677385e-07 5.8651534e-15]\n",
      "Sample 48: Predicted Label = 1, Probabilities = [3.0048279e-04 9.9761903e-01 2.0803583e-03], Uncertainty (std) = [0.00085741 0.00551265 0.00546349]\n",
      "Sample 49: Predicted Label = 2, Probabilities = [7.4522376e-13 3.3228909e-05 9.9996698e-01], Uncertainty (std) = [4.3071059e-12 2.0679431e-04 2.0679447e-04]\n",
      "Sample 50: Predicted Label = 1, Probabilities = [3.8052633e-04 9.9941748e-01 2.0201718e-04], Uncertainty (std) = [0.0015907  0.00224323 0.00162892]\n",
      "Sample 51: Predicted Label = 2, Probabilities = [3.0539266e-11 1.6898030e-04 9.9983108e-01], Uncertainty (std) = [2.4293664e-10 7.6994830e-04 7.6994667e-04]\n",
      "Sample 52: Predicted Label = 1, Probabilities = [5.3482585e-05 9.9943346e-01 5.1321293e-04], Uncertainty (std) = [0.00022982 0.00154663 0.00154029]\n",
      "Sample 53: Predicted Label = 1, Probabilities = [2.4445672e-04 9.9935842e-01 3.9694889e-04], Uncertainty (std) = [0.00033413 0.00075751 0.00067876]\n",
      "Sample 54: Predicted Label = 2, Probabilities = [1.0391555e-12 1.6665002e-05 9.9998361e-01], Uncertainty (std) = [4.5232273e-12 3.1648789e-05 3.1653271e-05]\n",
      "Sample 55: Predicted Label = 0, Probabilities = [9.999997e-01 3.932212e-07 9.375710e-16], Uncertainty (std) = [3.0170315e-06 3.0159938e-06 4.9064650e-15]\n",
      "Sample 56: Predicted Label = 0, Probabilities = [9.9988127e-01 1.1864850e-04 2.1817277e-12], Uncertainty (std) = [8.8007329e-04 8.8007632e-04 1.9275418e-11]\n",
      "Sample 57: Predicted Label = 1, Probabilities = [6.6555510e-03 9.9299598e-01 3.4846264e-04], Uncertainty (std) = [0.06485736 0.06489276 0.00303714]\n",
      "Sample 58: Predicted Label = 1, Probabilities = [1.2697070e-03 9.9870944e-01 2.0966552e-05], Uncertainty (std) = [7.5645489e-03 7.5614667e-03 7.2358882e-05]\n",
      "Sample 59: Predicted Label = 0, Probabilities = [9.9999774e-01 2.3908772e-06 2.6413379e-13], Uncertainty (std) = [2.1643133e-05 2.1649339e-05 2.6127960e-12]\n",
      "Sample 60: Predicted Label = 1, Probabilities = [1.5754024e-04 9.9774206e-01 2.1004861e-03], Uncertainty (std) = [0.0002547  0.00448282 0.00442029]\n",
      "Sample 61: Predicted Label = 0, Probabilities = [9.9999541e-01 4.7217959e-06 3.5526093e-13], Uncertainty (std) = [1.9180508e-05 1.9176814e-05 2.9542998e-12]\n",
      "Sample 62: Predicted Label = 1, Probabilities = [1.4245532e-04 9.9837226e-01 1.4852977e-03], Uncertainty (std) = [0.00046361 0.0051187  0.00510887]\n",
      "Sample 63: Predicted Label = 2, Probabilities = [7.1706551e-12 3.3953183e-05 9.9996620e-01], Uncertainty (std) = [6.7579463e-11 1.3490180e-04 1.3490165e-04]\n",
      "Sample 64: Predicted Label = 0, Probabilities = [9.9999994e-01 8.7661398e-08 1.9345963e-19], Uncertainty (std) = [6.4317805e-07 6.3861756e-07 1.2332913e-18]\n",
      "Sample 65: Predicted Label = 2, Probabilities = [2.2255106e-13 2.3714591e-04 9.9976295e-01], Uncertainty (std) = [1.6637688e-12 1.5325181e-03 1.5325203e-03]\n",
      "Sample 66: Predicted Label = 0, Probabilities = [9.999979e-01 2.132389e-06 9.394132e-15], Uncertainty (std) = [1.1876746e-05 1.1873784e-05 8.9371009e-14]\n",
      "Sample 67: Predicted Label = 0, Probabilities = [9.9999833e-01 1.6956178e-06 3.8840433e-15], Uncertainty (std) = [8.2081715e-06 8.2013330e-06 2.5449298e-14]\n",
      "Sample 68: Predicted Label = 0, Probabilities = [9.9999261e-01 7.5252838e-06 3.0046944e-15], Uncertainty (std) = [2.8190792e-05 2.8186158e-05 2.2217203e-14]\n",
      "Sample 69: Predicted Label = 0, Probabilities = [9.9998969e-01 1.0465674e-05 2.2360421e-12], Uncertainty (std) = [9.3435694e-05 9.3441791e-05 2.2201812e-11]\n",
      "Sample 70: Predicted Label = 2, Probabilities = [7.1077416e-10 2.3891309e-03 9.9761069e-01], Uncertainty (std) = [6.5566907e-09 1.7534763e-02 1.7534763e-02]\n",
      "Sample 71: Predicted Label = 2, Probabilities = [8.8371227e-13 3.4711305e-05 9.9996543e-01], Uncertainty (std) = [5.33713048e-12 1.17439529e-04 1.17438525e-04]\n",
      "Sample 72: Predicted Label = 2, Probabilities = [3.8189053e-12 6.5328495e-05 9.9993509e-01], Uncertainty (std) = [1.5690763e-11 2.2354607e-04 2.2354210e-04]\n",
      "Sample 73: Predicted Label = 2, Probabilities = [1.4572208e-13 2.1693490e-05 9.9997854e-01], Uncertainty (std) = [1.0905065e-12 7.5902397e-05 7.5895339e-05]\n",
      "Sample 74: Predicted Label = 0, Probabilities = [9.9999672e-01 3.4395780e-06 1.1675803e-13], Uncertainty (std) = [2.4770608e-05 2.4769648e-05 1.0436788e-12]\n",
      "Sample 75: Predicted Label = 1, Probabilities = [6.4044155e-04 9.9934036e-01 1.9381954e-05], Uncertainty (std) = [4.5106621e-03 4.5084725e-03 5.9374230e-05]\n",
      "Sample 76: Predicted Label = 1, Probabilities = [1.05239815e-04 9.99424994e-01 4.69784747e-04], Uncertainty (std) = [0.00016659 0.00117984 0.00118025]\n",
      "Sample 77: Predicted Label = 2, Probabilities = [3.2845130e-13 2.5202193e-05 9.9997485e-01], Uncertainty (std) = [1.3655955e-12 5.9718128e-05 5.9715225e-05]\n",
      "Sample 78: Predicted Label = 2, Probabilities = [1.3107666e-10 4.4630738e-03 9.9553686e-01], Uncertainty (std) = [1.1689796e-09 4.1636392e-02 4.1636400e-02]\n",
      "Sample 79: Predicted Label = 0, Probabilities = [9.99998629e-01 1.44504168e-06 1.21151775e-14], Uncertainty (std) = [7.2156686e-06 7.2136859e-06 7.9985552e-14]\n",
      "Sample 80: Predicted Label = 2, Probabilities = [2.1509695e-12 2.6827895e-05 9.9997330e-01], Uncertainty (std) = [1.12434385e-11 4.19910721e-05 4.19917742e-05]\n",
      "Sample 81: Predicted Label = 1, Probabilities = [1.6079078e-04 9.9610651e-01 3.7324841e-03], Uncertainty (std) = [0.0002837  0.00994287 0.00998027]\n",
      "Sample 82: Predicted Label = 1, Probabilities = [2.8739241e-05 9.9946070e-01 5.1059516e-04], Uncertainty (std) = [4.9440856e-05 1.6109365e-03 1.6157676e-03]\n",
      "Sample 83: Predicted Label = 2, Probabilities = [3.0765037e-12 4.5998175e-05 9.9995404e-01], Uncertainty (std) = [2.5772726e-11 1.9428905e-04 1.9428661e-04]\n",
      "Sample 84: Predicted Label = 2, Probabilities = [3.2569870e-13 4.3207634e-05 9.9995697e-01], Uncertainty (std) = [1.3701847e-12 1.3192563e-04 1.3192602e-04]\n",
      "Sample 85: Predicted Label = 2, Probabilities = [1.6626070e-12 4.5289074e-05 9.9995482e-01], Uncertainty (std) = [6.78907928e-12 1.12225491e-04 1.12226124e-04]\n",
      "Sample 86: Predicted Label = 0, Probabilities = [9.9997216e-01 2.7934693e-05 3.2151655e-15], Uncertainty (std) = [1.4115381e-04 1.4115822e-04 2.4236160e-14]\n",
      "Sample 87: Predicted Label = 0, Probabilities = [9.9999976e-01 2.7044442e-07 2.6921621e-14], Uncertainty (std) = [7.1624845e-07 7.0920976e-07 2.4348319e-13]\n",
      "Sample 88: Predicted Label = 1, Probabilities = [3.7860236e-04 9.9860746e-01 1.0141614e-03], Uncertainty (std) = [0.00193708 0.00402262 0.00357592]\n",
      "Sample 89: Predicted Label = 1, Probabilities = [2.0743117e-05 9.9922079e-01 7.5839576e-04], Uncertainty (std) = [4.4811215e-05 2.4563652e-03 2.4597661e-03]\n",
      "Sample 90: Predicted Label = 1, Probabilities = [1.9735051e-04 9.9960655e-01 1.9598885e-04], Uncertainty (std) = [0.00114165 0.00145031 0.00093006]\n",
      "Sample 91: Predicted Label = 1, Probabilities = [2.4264306e-04 9.9725121e-01 2.5060731e-03], Uncertainty (std) = [0.00093149 0.01407896 0.01406388]\n",
      "Sample 92: Predicted Label = 2, Probabilities = [5.5698329e-14 5.1730563e-05 9.9994820e-01], Uncertainty (std) = [3.5749260e-13 2.1859017e-04 2.1858948e-04]\n",
      "Sample 93: Predicted Label = 0, Probabilities = [9.9999863e-01 1.4629917e-06 2.6502028e-14], Uncertainty (std) = [7.7829427e-06 7.7807663e-06 1.9834374e-13]\n",
      "Sample 94: Predicted Label = 0, Probabilities = [9.9999970e-01 3.5556553e-07 4.0680039e-18], Uncertainty (std) = [1.3652976e-06 1.3670267e-06 3.2750678e-17]\n",
      "Sample 95: Predicted Label = 1, Probabilities = [2.7360962e-04 9.9803221e-01 1.6941219e-03], Uncertainty (std) = [0.00061063 0.00309076 0.00308047]\n",
      "Sample 96: Predicted Label = 1, Probabilities = [2.0639614e-05 9.9894327e-01 1.0362922e-03], Uncertainty (std) = [7.1423929e-05 9.1238655e-03 9.1257207e-03]\n",
      "Sample 97: Predicted Label = 1, Probabilities = [8.8321533e-05 9.9876738e-01 1.1443614e-03], Uncertainty (std) = [0.00051595 0.00731867 0.00731346]\n",
      "Sample 98: Predicted Label = 1, Probabilities = [1.6064130e-04 9.9842268e-01 1.4165601e-03], Uncertainty (std) = [0.00035115 0.0039011  0.00390648]\n",
      "Sample 99: Predicted Label = 1, Probabilities = [2.5836300e-04 9.9846739e-01 1.2742596e-03], Uncertainty (std) = [0.00039096 0.00257696 0.00258715]\n"
     ]
    }
   ],
   "source": [
    "# Example output with probabilities and uncertainty\n",
    "for i, (mean, std) in enumerate(zip(mean_predictions, std_predictions)):\n",
    "    # softmax_probs = np.exp(mean) / np.sum(np.exp(mean)) # Softmax to get probabilities\n",
    "    print(f'Sample {i}: Predicted Label = {predicted_labels[i]}, Probabilities = {mean}, Uncertainty (std) = {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export the reults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Save test predictions to a CSV\n",
    "test_df = pd.DataFrame({\n",
    "    'Prediction': predicted_labels,\n",
    "    'Probability_0': [p[0] for p in mean_predictions],\n",
    "    'Probability_1': [p[1] for p in mean_predictions],\n",
    "    'Probability_2': [p[2] for p in mean_predictions],  # Adjust based on num_classes\n",
    "    'Uncertainty_0': [u[0] for u in std_predictions],\n",
    "    'Uncertainty_1': [u[1] for u in std_predictions],\n",
    "    'Uncertainty_2': [u[2] for u in std_predictions] \n",
    "})\n",
    "\n",
    "test_df.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import save\n",
    "save(ae_attention_model, 'autoencoder_attention_classifier.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GluonTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
